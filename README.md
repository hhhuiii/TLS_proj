1. 扰动机制设计
（1）扰动类型：
● 基于TCP重传逻辑的扰动（合理性）：
  ○ 模拟真实网络中的丢包和重传行为，生成两种扰动：
    ■ 子序列重复（对应超时重传RTO，数据包重复）。
    ■ 子序列移位（对应快速重传FAST，数据包乱序）。
  ○ 扰动参数控制：
    ■ 丢包率（Packet Loss Rate）：控制扰动强度（如0.1%（理想网络）,1%（轻度拥塞）, 5%（中度拥塞）, 10%（重度拥塞）），前两种情况使用FAST场景，后两种情况使用RTO场景。
    ■ 捕获点位置（上游/下游）：决定扰动表现形式（重复或移位）。
（2）语义保留性：
● 强调扰动是协议相关的（TLS over TCP），因此重传行为不会破坏流量的语义特征。
● 通过理论分析或实验验证扰动前后样本的相似性（如计算序列编辑距离或余弦相似度），目前使用的是UMAP，只有当每类随机取两个样本时候才能得到能够接收的样本相似性变化。

2. 对比学习框架
（1）视图生成：
● 对同一原始样本应用同一场景下的两种扰动（如RTO重复 + RTO移位），生成正样本对。
● 负样本来自其他流量的扰动结果（类似SimCLR的取同一批次内其他所有样本作为负样本）。
（2）编码器与损失函数：
● 编码器：LSTM配合attention机制的Pooling共同作为编码器（适合时序数据）。
● 损失函数：NT-Xent损失，最大化正样本对的相似性，最小化负样本对的相似性。
（3）类似SimCLR的对比学习逻辑：
● 预训练pretrain：使用带注意力机制的双向单层LSTM作为编码器，对序列样本进行自监督训练。核心为通过不同的增强视图构造正负样本对，用NT-Xent损失最小化正样本对的距离，最大化负样本对的距离，学习富表征力表示，保存encoder供finetune阶段使用

损失函数：
NT-Xent-loss是SimCLR风格对比学习中使用的NT-Xent（Normalized Temperature-scaled Cross Entropy Loss）标准化温度缩放交叉熵损失
在自动拉近正样本的同时压低负样本的相似度，因为它是通过竞争式的softmax达到的，而不是显式最小化负样本相似度


● 微调finetune：
使用预训练阶段保存的自注意力机制结合LSTM结构的编码器，再有标签数据上进行微调训练，然后在测试集上评估和可视化分析（不一定用）


5. points
● 协议感知的扰动：不同于随机噪声，扰动模拟真实网络行为（TCP重传）。
● 无需标签的增强：对比学习利用无标签数据生成鲁棒表示。
● 实际意义：预计模型在真实网络环境（如移动网络、Wi-Fi）中表现稳定。
